{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "x6gWq3skaSFL",
      "metadata": {
        "id": "x6gWq3skaSFL"
      },
      "source": [
        "# CAPTCHA-Recognition-System (Train on Colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zJ82o0ywZ2aX",
      "metadata": {
        "id": "zJ82o0ywZ2aX"
      },
      "source": [
        "#### Step 1 : Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "276d7bae",
      "metadata": {
        "id": "276d7bae"
      },
      "outputs": [],
      "source": [
        "# Mounts your drive to /content/drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iHwXKRk-adL1",
      "metadata": {
        "id": "iHwXKRk-adL1"
      },
      "source": [
        "#### Step 2 : Copy dataset.zip from the data folder of the GitHub Repo to a folder in your Drive. Copy as Path for dataset.zip file from Colab Files and paste it below. ***Add Path Here.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XINtCYR1KdI7",
      "metadata": {
        "id": "XINtCYR1KdI7"
      },
      "outputs": [],
      "source": [
        "# Copy and Unzip using shell command\n",
        "!cp \"/content/drive/MyDrive/path/to/your/file.zip\" \"/content/\"\n",
        "!unzip \"/content/dataset.zip\" -d \"/content/\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oN-8EDNreFTQ",
      "metadata": {
        "id": "oN-8EDNreFTQ"
      },
      "source": [
        "#### Import all the dependencies (Colab has it all in-built, no need to pip install anything.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "52f3f878",
      "metadata": {
        "id": "52f3f878"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1uwPHqX5eYPr",
      "metadata": {
        "id": "1uwPHqX5eYPr"
      },
      "source": [
        "#### Step 3 : Pre-Processing the train images to Binary and removing noise. The unzipped images are directly processed and replaced as it is stored on Colab Disk for faster processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b_9T487bYzRC",
      "metadata": {
        "id": "b_9T487bYzRC"
      },
      "outputs": [],
      "source": [
        "# Threshold value for Binary Thresholding of CAPTCHA images\n",
        "thresh_value=220\n",
        "\n",
        "# Iterate through all the images in the parent folder and subfolders.\n",
        "for root, _, files in os.walk(\"/content/dataset\"):\n",
        "    for filename in files:\n",
        "        if filename.lower().endswith('.png'):\n",
        "            image_path = os.path.join(root, filename)\n",
        "\n",
        "            # Read image\n",
        "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            if img is None:\n",
        "                print(f\"Could not read {image_path}\")\n",
        "                continue\n",
        "\n",
        "            # Step 1: Median blur\n",
        "            blurred = cv2.medianBlur(img, 3)\n",
        "\n",
        "            # Step 2: Thresholding\n",
        "            _, thresholded = cv2.threshold(blurred, thresh_value, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "            # Step 3: Another median blur to clean noise on Binary image\n",
        "            final = cv2.medianBlur(thresholded, 3)\n",
        "\n",
        "            # Save processed image (overwrite original)\n",
        "            cv2.imwrite(image_path, final)\n",
        "            print(f\"Processed and replaced: {image_path}\")\n",
        "\n",
        "print(\"Processing complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1GEMml9ve4KU",
      "metadata": {
        "id": "1GEMml9ve4KU"
      },
      "source": [
        "#### Step 4 : Defining the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4cfdaf85",
      "metadata": {
        "id": "4cfdaf85"
      },
      "outputs": [],
      "source": [
        "class CaptchaDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    # Return length of the image\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    # Returns Tensor for image and label\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        return torch.FloatTensor(image), torch.LongTensor(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeHHYi_VfDZr",
      "metadata": {
        "id": "aeHHYi_VfDZr"
      },
      "source": [
        "#### Step 5 : Loading the Normalised Images and Sliced Labels to NumPy arrays. Data is split to Train/Val/Test reading from .csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "45a9f1d9",
      "metadata": {
        "id": "45a9f1d9"
      },
      "outputs": [],
      "source": [
        "def load_data(csv_path, test_images_present):\n",
        "\n",
        "    # Read labels CSV\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Create empty arrays for train, val, and test sets\n",
        "    train_images = []\n",
        "    train_labels = []\n",
        "    val_images = []\n",
        "    val_labels = []\n",
        "    test_images = []\n",
        "    test_labels = []\n",
        "\n",
        "    # Load and preprocess each image\n",
        "    for i, row in df.iterrows():\n",
        "        img_path = row['image_path']\n",
        "\n",
        "        # Prevents reading test-images when not present in the dataset\n",
        "        if test_images_present or not img_path.startswith('test-images/'):\n",
        "\n",
        "            # Read image\n",
        "            pos = img_path.index(\"/\") + 1\n",
        "            substring_path = img_path[:pos]\n",
        "            full_img_path = os.path.join('/content/dataset/'+substring_path, img_path)\n",
        "            img = cv2.imread(full_img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Normalize image (0-1)\n",
        "            img = img / 255.0\n",
        "\n",
        "            # Add channel dimension\n",
        "            img = np.expand_dims(img, axis=0)  # Shape: (1, height, width)\n",
        "\n",
        "        # Process label (6 digits)\n",
        "        label = row['solution']\n",
        "\n",
        "        # Ensure label is a string before slicing\n",
        "        label = str(label)\n",
        "\n",
        "        # Pad with zeros to ensure 6 digits\n",
        "        label = label.zfill(6)  # Pad with leading zeros to prevent losing zeros in the beginning of the label\n",
        "\n",
        "        # Convert each digit to numerical values\n",
        "        digit_labels = [int(digit) for digit in label[-6:]]  # Take last 6 digits\n",
        "\n",
        "        # Split into train/val/test based on directory prefix\n",
        "        if img_path.startswith('train-images/'):\n",
        "            train_images.append(img)\n",
        "            train_labels.append(digit_labels)\n",
        "        elif img_path.startswith('validation-images/'):\n",
        "            val_images.append(img)\n",
        "            val_labels.append(digit_labels)\n",
        "        elif img_path.startswith('test-images/'):\n",
        "            test_images.append(img)\n",
        "            test_labels.append(digit_labels)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_train = np.array(train_images)\n",
        "    y_train = np.array(train_labels)\n",
        "    X_val = np.array(val_images)\n",
        "    y_val = np.array(val_labels)\n",
        "    X_test = np.array(test_images)\n",
        "    y_test = np.array(test_labels)\n",
        "\n",
        "    print(\"X_train shape:\", X_train.shape)\n",
        "    print(\"y_train shape:\", y_train.shape)\n",
        "    print(\"X_val shape:\", X_val.shape)\n",
        "    print(\"y_val shape:\", y_val.shape)\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IiDLx1lzfoUm",
      "metadata": {
        "id": "IiDLx1lzfoUm"
      },
      "source": [
        "#### Step 6 : Defining the CNN Model Architecture. Six output layers are defined, one for each digit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0d5153b",
      "metadata": {
        "id": "a0d5153b"
      },
      "outputs": [],
      "source": [
        "class CaptchaCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CaptchaCNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # Calculate size after convolutions (for 200x50 input)\n",
        "        # After 3 max pooling layers with stride 2: 200/8=25, 50/8=6\n",
        "        conv_output_size = 64 * 25 * 6\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(conv_output_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "        )\n",
        "\n",
        "        # Output layers - one for each digit (6 digits)\n",
        "        self.digit1 = nn.Linear(512, 10)\n",
        "        self.digit2 = nn.Linear(512, 10)\n",
        "        self.digit3 = nn.Linear(512, 10)\n",
        "        self.digit4 = nn.Linear(512, 10)\n",
        "        self.digit5 = nn.Linear(512, 10)\n",
        "        self.digit6 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through convolutional layers\n",
        "        x = self.conv_layers(x)\n",
        "\n",
        "        # Pass through fully connected layers\n",
        "        x = self.fc_layers(x)\n",
        "\n",
        "        # Get output for each digit\n",
        "        digit1 = self.digit1(x)\n",
        "        digit2 = self.digit2(x)\n",
        "        digit3 = self.digit3(x)\n",
        "        digit4 = self.digit4(x)\n",
        "        digit5 = self.digit5(x)\n",
        "        digit6 = self.digit6(x)\n",
        "\n",
        "        return [digit1, digit2, digit3, digit4, digit5, digit6]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "S5OQCW1KgM0P",
      "metadata": {
        "id": "S5OQCW1KgM0P"
      },
      "source": [
        "#### Step 7 : Train the Model. Loss Function, Optimizer and BackPropagation. At the end of each Epoch; Train Loss, Val Loss and Val Accuracy is calculated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "434720c2",
      "metadata": {
        "id": "434720c2"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, num_epochs, learning_rate):\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), learning_rate)\n",
        "\n",
        "    # Assign GPU or CPU\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Calculate loss for each digit\n",
        "            loss = 0\n",
        "            for i, output in enumerate(outputs):\n",
        "                target = labels[:, i].to(device)\n",
        "                loss += criterion(output, target)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total_digits = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images = images.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Calculate validation loss and accuracy\n",
        "                for i, output in enumerate(outputs):\n",
        "                    target = labels[:, i].to(device)\n",
        "                    val_loss += criterion(output, target).item()\n",
        "\n",
        "                    _, predicted = torch.max(output, 1)\n",
        "                    correct += (predicted == target).sum().item()\n",
        "                    total_digits += target.size(0)\n",
        "\n",
        "                    val_accuracy = correct / total_digits * 100\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss/len(train_loader):.4f}, '\n",
        "              f'Val Loss: {val_loss/len(val_loader):.4f}, '\n",
        "              f'Val Accuracy: {correct/total_digits*100:.2f}%')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QAc1IJ9HhPGl",
      "metadata": {
        "id": "QAc1IJ9HhPGl"
      },
      "source": [
        "#### Step 8 : Evaluate the Model with calculating accuracy for Complete CAPTCHAS and Individual Digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "22fd1250",
      "metadata": {
        "id": "22fd1250"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "\n",
        "    # Assign GPU or CPU\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_predicted = []\n",
        "    all_actual = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Get predictions for each digit\n",
        "            batch_predictions = []\n",
        "            for i, output in enumerate(outputs):\n",
        "                _, predicted = torch.max(output, 1)\n",
        "                batch_predictions.append(predicted.cpu().numpy())\n",
        "\n",
        "            # Transpose to get predictions per image\n",
        "            batch_predictions = np.array(batch_predictions).T\n",
        "            all_predicted.extend(batch_predictions)\n",
        "            all_actual.extend(labels.cpu().numpy())\n",
        "\n",
        "    all_predicted = np.array(all_predicted)\n",
        "    all_actual = np.array(all_actual)\n",
        "\n",
        "    # Calculate accuracy for complete captchas\n",
        "    correct_captchas = 0\n",
        "    for i in range(len(all_predicted)):\n",
        "        if np.array_equal(all_predicted[i], all_actual[i]):\n",
        "            correct_captchas += 1\n",
        "\n",
        "    captcha_accuracy = correct_captchas / len(all_predicted) * 100\n",
        "\n",
        "    # Calculate accuracy for individual digits\n",
        "    digit_correct = np.sum(all_predicted == all_actual)\n",
        "    digit_accuracy = digit_correct / (all_actual.size) * 100\n",
        "\n",
        "    print(f' Model Captcha Accuracy: {captcha_accuracy:.2f}%')\n",
        "    print(f' Model Digit Accuracy: {digit_accuracy:.2f}%')\n",
        "\n",
        "    return captcha_accuracy, digit_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zFk6AQnpiFE0",
      "metadata": {
        "id": "zFk6AQnpiFE0"
      },
      "source": [
        "#### Step 9 : Run all the functions and save the model in your Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7101900d",
      "metadata": {
        "id": "7101900d"
      },
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Set False if no test images in dataset.zip\n",
        "test_images_in_zip = False\n",
        "\n",
        "# Load data\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_data('/content/dataset/captcha_data.csv', test_images_in_zip)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CaptchaDataset(X_train, y_train)\n",
        "val_dataset = CaptchaDataset(X_val, y_val)\n",
        "test_dataset = CaptchaDataset(X_test, y_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# Initialize the model\n",
        "model = CaptchaCNN()\n",
        "\n",
        "# Set the number of epochs\n",
        "num_epochs = 300\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# Train the model\n",
        "trained_model = train_model(model, train_loader, val_loader, num_epochs, learning_rate)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(trained_model, val_loader)\n",
        "\n",
        "# Drive path to the save the model\n",
        "custom_path = r'/content/drive/MyDrive/CAPTCHA_models'\n",
        "os.makedirs(custom_path, exist_ok=True)\n",
        "\n",
        "# Save the model\n",
        "torch.save(trained_model.state_dict(), os.path.join(custom_path,'captcha_model_best.pth'))\n",
        "print(\"Last Model saved successfully!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
